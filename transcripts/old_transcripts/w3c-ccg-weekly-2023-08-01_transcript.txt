 Good. Okay. So, I'm really excited to welcome Joel to talk with us today. He, Harrison sent out a link to his article and I just had a chance to read it and was telling him as we were coming on and getting started that it was very helpful and very accessible. So, I hope you all have had a chance to look at it, but if you have not, he is going to be kind of talking through it for, you know, a bit of the conversation today and then hopefully we can actually have a discussion around it. And I know Harrison sent out a number of questions that I think will be really good for us to start the conversation. I think one of the things that is happening for me is that I'm getting a more and more robust understanding of DIDS by every time we have one of these conversations. And so I'm looking forward to today, I think what I learned from the article helped just sort of build that context even more. And so I'm hoping that I can come away with even just a clearer sort of two sentence description for those folks who I encounter on a really regular basis who don't know what it is. So, anyway, but let's jump into just kind of our quick little housekeeping staff and then we'll let Joel take over. Yes, you all know and are all committed to is that we follow a code of ethics and professional conduct. And if you want to refresh yourself on that, there is a link in the agenda to it. We welcome anyone to participate in these calls and encourage that participation. However, if you're really wanting to be involved in the nitty gritty work that we're doing, then I would invite you to sign the IPR agreement and the link to that can be found on the website on our it should be able to be found on our website too, but it also can be found in the agenda. And it will require that you have a W3C account. But just to know that that is free and participation in the community group is also free. We do keep a recording of and minutes of this meeting. And we use JITC to do that if you want to participate in the call. I'm looking through and I see most of you are familiar faces. So you know to cue yourself by just typing Q plus in the chat and that will put you on the queue and I will be the one today who is attempting to manage that queue. So now comes one of my favorite parts of the day, which is introductions and reintroductions. So if you are new to this group or if you haven't come off mute in a while and you'd like to just remind us who you are now is your opportunity to do so. So please go ahead and hit that Q plus button. Alan, I noticed you came off mute. Yeah. I don't usually attend this meetings, but I attend a lot of the W3C meetings where they're talking about object capabilities just so that people don't make, I'm trying to keep people from making the newbie mistakes that I made when I was a capability newbie. Awesome. Well, welcome. I'm glad you're here. Anyone else want to come off mute and say hello? Okay. How about introductions about announcements and reminders? Anyone want to add themselves to you for that? Yeah, yes, please. Hi, just a reminder that the Internet, I don't know if it's coming up October 10 through 12 in Mountain View, California. And early bird registration, I think, ends at the end of this week. So yeah, we hope to see you there. I will be there. I'm really excited about it. It sounds like a fabulous. I definitely hope to see lots of folks on this list. Any other announcements and reminders? Dimitri, could I put you on the spot to give kind of a recap of the data integrity work that you've been working on? Sure, I think Mona might be a better candidate to do that. So the verifiable credentials working group, the 2.0, is also developing a data integrity specification as part of its deliverables. And it is a general purpose way to sign essentially JSON objects. And there's a general mechanism and a number of specific signature suites using key types that we're all familiar with. So there's the elliptic AdWords curve, RSA, the NIST curves, and so on. The data integrity works either if you're signing linked data objects using JSONLD or it also works using non-linked data JSON objects using simple JSON conicalization. And in fact, that part is currently being adopted by the Fediverse, so essentially social media such as Mastodon and others. So the specs are both the main spec and the suite specs are on track to be delivered with the rest of the working group specs. Great, thank you. Manu. Yeah, just to add to what Dimitri was saying. So the good news, I think with the data integrity suites is as of last week, we only have three issues on the main spec and three issues on the EDDSA spec that we need to resolve before we think the specifications are ready to go into the candidate recommendation phase. That's basically where you freeze the specifications completely, tell the implementers that they're ready for implementation and to integrate them with the test suite. So the good news there is that I think we're a little ahead of schedule there. Clearly we can't say that we're done yet. We will learn things as people more broadly implement it. But the other good news with those data integrity test suites, which were all incubated in the industry, is that we have multiple independent implementations for them. Three for ECDSA, three for EDDSA, seven for the ones we used for the plug fest last year. And that is without actually announcing that we're ready to have people integrate with it. On a good glide path for those data integrity items, that's it. Great. Thank you. I've noticed that we've had a whole sort of influx of folks come in and just the last little bit. And so I want to read, sort of come back to introductions and re-introductions and see if there is anyone who is joining us today that is new or just wants to come off mute and kind of say hello. So I'll kind of revisit that topic. All right. And I'll say again to everyone that's here now, if you have announcements and reminders, come put yourself on the queue. Okay. Well, then that concludes the housekeeping portion of the call today. And so I'm going to go ahead and turn it over to Joel, who is going to talk a little bit with a talk about dance with us Joel. Joel and I practice screen sharing. So it should be should work well. Everyone, happy to be here. So let's see if I can get the slides going. Okay. How about that? Yep, we see them. All right. Great. So these are slides that actually put together somewhat over a month ago in the article published, also over a month ago. So I want to just excuse in advance that this is not super fresh in my memory. But I think we can still have a good discussion. And I would also say if that's okay, like feel free to interrupt if there's anything unclear as I'm going through this. I know we'll have time for questions at the end as well. Okay. So what are we going to be talking about today is something that I've called generative DAD maximalism. And this is something that kind of arose past. I've been building these centralized protocols that use the IDs as like the account mechanism and struggling with kind of how to support multiple DAD methods while retaining decentralization of our corporate protocol. So before I jump in, it's like very briefly about myself. I've been working in the web page slash blockchain space since 2015 and working with the IDs since 2016. I was part of the you port team, which was one of the early projects doing the idea stuff back back then. I'm a co-founder of a company called three box labs. And our main focus is building a decentralized data network called ceramic. And ceramic leverages the AES is like the main account model for publishing data into the network. Right. So for the agenda today, I'm going to start talking about like why the IDs can't interoperate. And to dive a little bit deeper into that like why do we need to build the in the 80s. And in the first place. Then we'll talk about what generative DADs are and how they can be used together with object capabilities. And that will just have time for general discussion at the end. So for people who actually read my article before hunt, this is kind of just like a reiteration of that. Right. So let's dive in. Why can't DADs interoperate? Well, I think the main reason for this is that we have this specification that allows anyone to kind of implement the AES. Whatever kind of back end that they feel appropriate. And this is led to less many of you know, I think the numbers probably way larger now, but over like 160, 170 probably at this point. The idea methods in the registry is great. We get to experiment a lot. But if you want to build an application, you like we have to pick one or a few methods that you support. And so why can't we support all them? Why is that so hard? Well, different DAD methods requires different verifiable data registries. In most cases where you actually want to have a decentralized data registry, you need to rely on some sort of blockchain. So this could be Bitcoin. It could be Ethereum. It could be some other network. And in the case where you're relying on one blockchain, say Bitcoin or Ethereum, you can run this on commodity hardware. And you can potentially even support multiple different DAD methods that are supported by that individual blockchain. But if you want to support multiple different DAD methods that rely on multiple different blockchains, you're in trouble. You basically won't be able to run and resolve these DADs on commodity hardware. You need to kind of outsource that work to a server somewhere. And then we're kind of losing some of the properties of DADs that we actually want them to be decentralized. We want them to be trust minimized. And in many cases, the DAD methods on Bitcoin or Ethereum actually requires you to run a full node. It's not enough to run a client. In some cases, I like that it might be enough, but definitely not in all cases. And especially if you try to build a full-aid central set application where you want the user to have kind of run the full decentralized application, this is this aspect of like, supporting multiple DADs across blockchains is simply not going to work. And there are some great efforts to have some sort of universal resolver. I think there's like repo that just like tries to integrate a bunch of DAD methods into one single repo with a bunch of Docker images. It's great, but the problem is you can only feasibly run this on my big servers and can't run an application that requires users to run this locally. It's simply too much. And so the question that comes to next is like, okay, so what does actually using these blockchains give us? What these blockchains are very powerful data registries allowed to do is how mutability over DADs. The last is to have a history of like which keys were authorized to act on behalf of this DAD at the point in time. And that's kind of why we want the ability of the DAD, right? Like the historical changes of the DAD enables mutability. And so I would say there are two main things. One is this key rotation. The other one is something that DADs also allows us to have a place to store some metadata. It's usually like a pointer to some service, I guess in general, it's called services on the ADs, but pointing to some server or to some other kind of resource. And so one thing that noticed was I was thinking about this is like, okay, DADs actually do two very different things. One is supporting key rotations, and one is having this registry of metadata. So what I'm talking about here is mainly just like thinking about the key rotation aspects of the ADs. Personally, I'm not convinced that also having a metadata registry inside of a DAD is like, we're kind of trying to solve two kind of very different problems with with one primitive. But I want to dive too much into that right now. Okay, so there's this great article written by, I think, Wayne from Spruce ID. And there he talked about, they actually can think of different DAD methods as having different traits. So all of this, these DADs in this example, like the key, the PKH, red, you know, and so on, supports the second P256K1 key type. The key in the PKH are purely generative. And the other ones are have the ability to both the keys. So what is a generative DAD method? It's basically a DAD method that doesn't support any type of key rotation. Instead, you can basically generate the DAD document from only knowing the DAD URI itself. We can essentially in some shape or form, the URI includes the public key. So for the key, you actually have to be coded the entire public key for the PKH. You have encoded the hash of the public key. Okay. And so the nice property about generative DADs is that we don't actually rely on any ledger. We can use them anywhere without needing to synchronize a blockchain or look up a DNS name like in the web or contact some centralized server. We can just use them locally. And so that's very nice. But we actually want key rotation, right? Like we want the ability to revoke keys and to rotate keys. And this is where I think the combination of a generative DAD paradigm with object capabilities becomes a really powerful way of having primitives that enable each other. So object capabilities can be used to delegate control over DAD in some sense. And this is not like a talk about or like a discussion of what object capabilities are in detail. I'm just going to talk about some of the things that I've been seeing in this space. There are some emerging standards in kind of the web 3ish community. Recap is an object capability based on sign in with Ethereum. So basically it makes any Ethereum wallet into a wallet that also can be a DAD and delegate control to session keys or other DADs essentially could be a key in your browser, or it could be someone else is the idea. You can is an emerging standard in the IPFS community and is being used by a number of different projects. And this is based on JWT's. And we've actually been working closely with the spruce team and the phishing team who each are responsible for recap and you can to align the format for. The recap and you can capabilities. And so we can actually represent them in a very similar way and have interoperability in these two. Then I wanted to mention also change groups and I think this is kind of critical to terms that like how we can actually have something like the same properties we would have with verifiable data registry. With only general DADs and object capabilities. So chain proofs is basically an object capability that encodes a state proof from a blockchain. So for example, in Ethereum, every block there's the there's a hash that's basically the root hash of the state of the entire blockchain. And given that hash, I can actually generate a miracle proof that says the owner, for example, the owner of this NFT is accounts zero X, A, B, C. And I can verify this proof and verify that this block header is included in the blockchain for this chain proof. And I can know that, okay, this account was actually the owner of this NFT at this point in time. And this is really powerful because then I can verify any state about the blockchain using only a like client. And essentially this enables us to have DAD methods that are based on various types of ancient state without having to run a full node in that blockchain. And actually running one or multiple light clients locally on commodity hardware is way easier than running call modes, which should be self evidence. So I just want to talk about an example of how we could use object capabilities to delegate control over. Let's say here we have the ID example a, and we delegate basically the star basically pull access to the DADB. So now it's essentially DADB could do anything that the data could do. And this example, the idea here, think of this is, is that a generative DAD that doesn't allow you to do any sort of key rotation. Think of you could think of this for example, as you start did key. Now, did be basically is makes a right to some some resource, and we call this data one. Now, at some later point in time. We issue a provocation of the essentially the object capability that we gave to the DB. And this could be like either you can or recap, it doesn't really matter. And we revoke the access that's. DADB had. Okay, so and here down at the bottom, we have the time. So we can see that data one was written some kind of time and data B or sorry, the revocation of the data. Now we run into a problem here, when, because how do I know here if we don't have a strict simple time, but maybe DADB did another right of data time to. And from an external observer, I might not have seen this this revocation yet. But we need some sense of time here. And if there's just no sense of time, we only have object capabilities and. And this data rights that happen at some opaque point in time. We can't really know like when this was revoked or not. And what this actually means is we need a verifiable data issue. We need to be able to timestamp. What point in time does this replication happen? Did this replication happen before data one was written? Or did it happen after? And to get that information, we need to have some way of time stamping. And this time stamping. Yeah, it needs a very familiar strategy, but it could be a like client. We could simply just like register some some mercury or some hash on chain. That can be proven with only like client proof, similar to chain proofs that I mentioned before. But okay, like now we need a verifiable data. We are back to where we started. And we need to select essentially one blockchain or have to have some centralized system that runs all the blockchains. But I think it's slightly more nuanced. So in the case where we have immutable VAD, we essentially have to pick one. If we want to have it fully decentralized to pick Bitcoin or make it here or some other blockchain. And then that's it. Well, in the case we use object capabilities and generative deities. The generative deities are kind of universally compatible. We just need some code to verify those locally. Then on top of that, we're using object capabilities. In some cases, these are we can use them wherever as well. In some cases, they require some sort of like client, like for example, if we use these chain proofs. If it's a chain proof of the Ethereum blockchain, then we of course need to like client of the Ethereum blockchain. But we can sort of like mix and match the object capabilities and potentially support across multiple chains. Finally, the revocation registry, which is what I'm calling the verifiable data registry, which time stamped the subject capabilities. The point that happened. Here we actually need to pick one essentially chain or verifiable data registry, which we use for our application. But as you can see, this gives us a lot more flexibility because we can have way more interoperability on these lower layers and have make this constraint in our revocation registry. Right, so you might wonder at this point, like, okay. Well, what if I want to use a mutable, the ID and object capabilities. In that case, you're kind of picking the worst of both worlds, in my opinion, because you both need to choose a blockchain system for a mutable the ID, and then choose one for the revocation registry and they kind of like have to overlap unless you want to like have this drive towards centralization because you can run it on the commodity hardware. Okay, so let's talk about examples of generative VAD methods. Like, what can we actually do, which what type of things could is reasonable here. I too mentioned already, so the key, most of you are probably familiar with this purely generative. It can work with, you can't recap. Yeah, like very flexible. Did PGH also purely generative works with recaps slash signing with Ethereum or there are similar things designer with the teams for other blockchain worlds. Benefit of the PGH is there's already a wide distribution of cryptocurrency wallets out there that people are using. As it enables us to have wide distribution. Then there are other DAD methods that are currently not generative or doesn't exist yet but did NFT not currently generative, but it could be changed to make to be made generative. Because simply it's like based on the identifier generator static documents and then we could use this. Shame proof to essentially as an ugly capability have a state proof of, for example, the Ethereum blockchain that. Hey, this particular address, AKA did PGH is the owner of this NFT. And potentially them delegate further to other deities, but we can have like a full proof of like, okay, here is at this point in time. This was actually the owner of this NFT. And so you need a like plan to verify the object capability, but the DAD itself is purely generative. Very similar, we could imagine a DAD method called the EBM that on this, which essentially is be like any function call to any contract on a theorem can be used as a DAD. This also rely on this shame proof methodology. Then look at, let's look at some kind of existing DADs that are not currently generative, but I think we could imagine them reimagine them as generative DAD methods. For example, the DNS right now it looks up a DNS record when you resolve it. And there are probably people who can correct me on this on this call, but in theory, we could, I think, make an object capability that includes a DNS proof that you can verify the signature and kind of the delegation chain, rather than like always resolving the DAD. The DNS did document basically contains like, hey, this is the DNS record as long as you have another DAD that can provide a delegation proof through some DNS record. We can have this, we can see that this delegation chain is valid. Similarly, with the mail to, we could potentially do something as well using the TKM proof to also do that kind of delegation. And I know there's a lot of nuances here that runs more the skeptic, but this is more kind of awesome. It was just a sample of how we can move more in this direction. All right, so that was all of the kind of content that I prepared the article, I think, a little bit more in detail, but I hope this helps. So, I'll kind of pause here and then see if there are any questions. Thanks Joel. Thanks a lot. And before I start, the queue is already going up before I start calling on a queue. I don't want to just make sure that I got my understanding. This right and have you kind of help walking through my space. So I have a wallet and I use it to store primarily open badges and C L R's that are from education, man script. So, I'm connecting with somebody who's going to issue me one of those credentials. I'm sending them my my did web and they're authenticating it back and forth. But if I wanted to connect to somebody to use a different good method, they would be like, no, sorry, we can't, we can't communicate. So your, your way would be basically next to it to allow for that did method to allow like a connection between those did methods so that I could use my usual did method to connect. Is that right? And how is it wrong? So I think actually you could maybe have some kind of Oracle system that acts as like an interoperability layer for these types of sort of more centralized the methods like did web. Did web relies on the DNS naming system and it also relies on someone running a server somewhere. But if you can have like some Oracle system that the test to like, hey, yeah, this was this this did web result to this. The document at this point in time. Then you can sort of trust this Oracle network and use that as an object of ability. So in theory, yeah, I guess you could have that sort of interoperability thing. This is not really what I was like trying to convey here. The primary thing I'm trying to communicate here is. When if we want to make a person that is fully decentralized and doesn't rely on kind of centralized servers to resolve the methods. What are what is the kind of trade off space and like how can we make different DAD methods as interoperable as possible. So it's kind of like the DAD space is pretty large. There's like a lot of different things. There are some methods that are like highly centralized or some methods that are like highly decentralized. And I know there's like someone has been working on this rubric and whatnot. But kind of what I'm trying to do is like this space of the centralized DAD methods like how can we make them more interoperable and make them something that we actually drag more usage of rather than just like using these more centralized DAD methods. As it's like a cop out almost. So maybe a maybe a better example would be someone has one of these very decentralized methods and they want to communicate where they more centralized method. They need a way to do that. Yeah, it's more like if you want to build an application and you want to use this to not rely on kind of centralized systems. But you still want to support as much stuff as possible. How like what are the right constraints for you to consider when you're building your application. Ah, that's very helpful. Got it. Thank you. Okay, let me get over here to the queue. Uh, Alan. Yeah, I want to talk about the revocation. I think it's easier than you made out because an object capability has to designate a specific object. Or to be an object capability. And therefore to revoke you only have to notify the service that hosts that object. No, to no longer honor that capability. Is that conform to what you were saying? I didn't get that from what you said. I think that's fine in the case where you have a service. Right. So, for example, in the protocol we're building. We're not assuming that there's one service that hosts your object. Your object is a self certifying data structure that could be living at any number of nodes in the network. And so what we need is a way for any note to synchronize this data structure and be able to verify the integrity of this data structure. Trustlessly. And for that to be the case, we need to be able to know like what point in time when this was this object capability revoked. So this is not a mutable object. Because otherwise you have to synchronize any updates, in which case you can use the same mechanism to synchronize revocations. Yeah, I think I think that's the point. Yeah, you would use the same method to synchronize revocations. But if you want to verify the integrity of historical. Events in this data structure. You need to know that, hey, this key B was valid at time one. Time to it got revoked and the time three was not valid. And I need to have this information if I want to know the previous event that happened at previous point in time is still to be considered valid. Time is a tricky thing. Who's who's time. The only one that makes sense again is the place that's going to do the update. And if that's distributed, that's a real tricky problem. There are other ways to handle it. Maybe we should talk offline. For example, I was going to say, for example, a forwarding proxy that you can just stop. To me, this is the problem that blockchain solve, right? Like, if you read the Bitcoin, right, they were the way the way they set the objective, the stripes it is as the decentralized time stamping service. And I think that's like a really powerful thing to leverage in these cases. Right. Then you can just put the revocation on the blockchain. And when you get a request, you can see if it's been revoked. Yeah, I think I think putting it on the blockchain might be expensive. What you can do is you can put a bunch of replications in a mercury, put the root of that function, and have some kind of other peer to peer gossiping or synchronization mechanism. Right. Okay. I have to learn more about your system, but I think I think that problem is not as difficult as you made it out to be. And I don't think that time stamps are. You have to think very carefully about what time stamps me. For sure. Manu. Yeah, thanks, Kimberly. This was great, Joel. You know, I think you hit on a number of challenges that we have in the, in the did ecosystem. And I think it's really interesting how you, you know, broke the part broke the problem up into multiple parts. Right. So one of them is, it is interesting to be able to classify these did methods by the trade that they have. And then you someone say like it's a feature set. So did key and did PCHs feature set is different from did web and which is different from did I on and did BTC and the Ethereum based. So I thought that was the one thing that you highlighted or re highlighted that was really important. I thought the other really interesting thing that you're highlighting here is that there is a way to use object capabilities as a binding mechanism between two different did methods, meaning, you know, the, the cryptographic delegation is a useful thing to have. And finally, the way that you spoke about the time stamping services and Alan, you know, I think of them as, you know, ordering services as well, meaning like you have to understand the order in which these things happened in and if you, and you need to be able to anchor that to some common trust model. So I totally agree with you, Joel. That's largely the service that blockchains provide going all the way back to the original Bitcoin paper. I think the challenge here, this is in like, this is not a solved problem. Right. I mean, if we solve this problem, then this is, that would be huge. It would allow us to, you know, potentially largely reduce the number of did methods they are and so on and so forth. I think that the challenge is, you know, putting the pieces together in the right order. And it's what Alan kind of highlighted. It's like at some point, if you start depending on a time stamping service, then it raises the question, well, isn't it just easier to store all the data there as well. And as you said, Joel, well, that might, you know, rocket the cost of the transaction up and we don't want to do that in a way to mitigate that as Markle. So we've got all this stuff kind of bubbling around at the soup of potential, you know, solutions that we could provide. And I think that one of the biggest challenges here, Joel, I'm interested in your thoughts on this is the complexity that this adds to implementers, the wallets and things of that nature. So we're already mired in complexity right now with all the different did methods and requiring a effectively universal resolver to be able to resolve all of them. Do you feel like the level of complexity is the same if we did the O cap and delegation approach with the time stamping service versus a universal resolver like how would you rate the complexity of both of those solutions is one easier than the other. That's it. Well, first of all, I think I have a feeling that even if you have a resolver that this universal or whatnot, you still probably want to rely on some kind of public capabilities at some point. And now you're kind of stacking complexity on top of each other, which seems not like the greatest idea. And so my intuition is tells me like, let's just put the complexity in the way to revoke object capabilities and keep the kind of lower level cryptographic primitives as simple as possible. I do think the object capability registry and like ability to revoke that is not super simple and it's up to salt like if we want like one universal solution to that. But I think that it could potentially be something that applications chooses like hey, my application over here has the simple revocation approach. Another application over here has some other approach to that. But we can still interoperate on these like general to the methods and different representations of object capabilities. And so resolver approach works. If you're fine with having your application rely on some service somewhere that you used to resolve the methods. If you're not fine with that, you want more resilience and you want your application to be more of a more peer to peer nature. And that would be a trade out that you want to make. So can you give me an example of, of the type of use case where I where I would want it to be. And then if you have an NFT wallet like you talked about before that that would be maybe a place or is there a better use case that you can help me picture. Maybe I can give an example of how we use generative DAD methods and object capabilities in the protocol and building ceramic. That'd be great. Maybe expand from that. Basically all accounts in ceramic is either a material account or some other blockchain account, a majority of them are used like a theorem accounts for this we use DAD PCH. So the normal flow when a user comes in application that uses ceramic as kind of a data storage network is that user arrives to application in the background, the application generates a data key, the public key that is, and it also contains a list of resources that this key is allowed to write to. You sign this message with your wallet and the application gets the message and the signature back. And so in our case that resource is a ceramic URL, basically an IDE for a unique resource. And as long as this, the key to session key can produce a signature that includes the hash of this object capability and also passes along this object capability. Any ceramic network peer can validate the integrity of this object capability and see that. Okay, this session case actually allowed to write to this resource. So that's how we use object capabilities right now in ceramic. You asked about, can I create what about an NFT or something like this? We could imagine instead of a resource being owned by like an Ethereum address, it could be owned by an NFT. And in that case we would have like one extra step of the location. So when the user comes to an application. The application simply generates a state proof from a theory showing that like there's a proof from the NFT to the owner. And then there's a session key and there's a proof from the. Ethereum address to that session key and as long as the session key can present these two object capabilities together, it can write to this resource answer. This is not something we have implemented yet though, but it's something that we're kind of planning to do. And we wanted to do it in a way where you only kind of require have like a light client's requirements. Okay, that's very helpful. Thank you. Demetri. I just wanted to add to. To what was said and to answer your question. So think of it as being able to to delegate to an FT wallets or any kind of cryptocurrency. Allows you to access the audience of. People who use things like MetaMask who have NFTs, right? It's less that you should choose it for a new use case and more. It gives you a wider audience of people with wallets. Yeah, exactly. As far as I know the kind of cryptocurrency ecosystem and distribution of walls is the largest distribution of private keys or like public key infrastructure. We're actually and like actually people have control over their own keys, which I think is very aligned with what the whole kind of deity ecosystem is trying to achieve. Great. Thank you both. Alan. One thing you didn't mention if you have a time stamping service, you can make short lived capabilities and just rely on the exploration time instead of explicitly revoking. That's right. Yeah, and that's actually what we're doing for our object capabilities that we use. However, you still need to notarize the events that you produce using that object capability. Because if. If I produce a bunch of events that at the time one and the object capability expires the time to the time passes and now it's time three, I send basically my ideas and those events to your peer. From your perspective, would you see like, yeah, it's time three, but you have a bunch of things that are signed with the object capability that was expired at time two. So I'm not going to accept them as valid. However, if you have approved that this was time stamp before that, you can accept those. Right. And that's just a matter of how you handle the exploration time. Yeah. But it resolves the. The problem you mentioned of distributed resources and needing to get the revocation signal to them, you could just rely on the timeouts. The exploration times. Yeah, I mean, no less you have an exploration time. It's like too far into the future and you actually want to revoke a key. Well, that again, that's why I don't like just why I don't like using exploration times, but certainly a good fallback. And if you have a distributed system, sometimes it's just the simplest thing. The hard part actually of the expiration time is you didn't want to revoke. So you have to reissue the capability. That's typically the trickiest part. Yeah, and for us, actually, that's very simple because if you come to an application, the application notices that the session key has some capability that's been expired. It's trivial to generate a new one. I'm gonna ask you to sign in your message. So your situation, it's actually easier than in most. Yeah. All right. Anyone else with a question for Joel? All right. Great. Thank you so much Joel for coming in sharing this information with us. Oh, Ted. Yes. A quick request for a link to the deck. Yeah, sure. I'll see if I can share this. Phil, we have a couple minutes. You want to pop on and ask your question? Thank you, but I'm pretty wiped out from COVID at the moment. So. Oh, no, well, I'll ask it for you then. Thank you. Phil is wondering, does this allow you to reissue keys and map them to the deprecated key? I'm not sure I fully understand the question, but you could definitely. I don't know what we issue a key means, but you can revoke a key and delegate the same access that that key has to a different key. I mean, in theory, you could revoke a key then like, like, give the capability again. Yeah, like the object capability model is very flexible. Flexible is good. All right. Thank you, everyone for coming today and engaging in this conversation. I learned a lot and deepening my knowledge. I'm not sure I'm ready to explain it at a. In the elevator, but I'll work on it. So thank you, again, Joel. Thank you, everyone for coming and we'll see you next Tuesday. Thanks, everyone. You